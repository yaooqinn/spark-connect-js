//
// Licensed to the Apache Software Foundation (ASF) under one or more
// contributor license agreements.  See the NOTICE file distributed with
// this work for additional information regarding copyright ownership.
// The ASF licenses this file to You under the Apache License, Version 2.0
// (the "License"); you may not use this file except in compliance with
// the License.  You may obtain a copy of the License at
//
//    http://www.apache.org/licenses/LICENSE-2.0
//
// Unless required by applicable law or agreed to in writing, software
// distributed under the License is distributed on an "AS IS" BASIS,
// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
// See the License for the specific language governing permissions and
// limitations under the License.

// @generated by protoc-gen-es v2.2.3 with parameter "target=ts,import_extension=none,js_import_style=module"
// @generated from file spark/connect/expressions.proto (package spark.connect, syntax proto3)
/* eslint-disable */

import type { GenEnum, GenFile, GenMessage } from "@bufbuild/protobuf/codegenv1";
import { enumDesc, fileDesc, messageDesc } from "@bufbuild/protobuf/codegenv1";
import type { Any } from "@bufbuild/protobuf/wkt";
import { file_google_protobuf_any } from "@bufbuild/protobuf/wkt";
import type { DataType } from "./types_pb";
import { file_spark_connect_types } from "./types_pb";
import type { Origin } from "./common_pb";
import { file_spark_connect_common } from "./common_pb";
import type { Message } from "@bufbuild/protobuf";

/**
 * Describes the file spark/connect/expressions.proto.
 */
export const file_spark_connect_expressions: GenFile = /*@__PURE__*/
  fileDesc("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", [file_google_protobuf_any, file_spark_connect_types, file_spark_connect_common]);

/**
 * Expression used to refer to fields, functions and similar. This can be used everywhere
 * expressions in SQL appear.
 *
 * @generated from message spark.connect.Expression
 */
export type Expression = Message<"spark.connect.Expression"> & {
  /**
   * @generated from field: spark.connect.ExpressionCommon common = 18;
   */
  common?: ExpressionCommon;

  /**
   * @generated from oneof spark.connect.Expression.expr_type
   */
  exprType: {
    /**
     * @generated from field: spark.connect.Expression.Literal literal = 1;
     */
    value: Expression_Literal;
    case: "literal";
  } | {
    /**
     * @generated from field: spark.connect.Expression.UnresolvedAttribute unresolved_attribute = 2;
     */
    value: Expression_UnresolvedAttribute;
    case: "unresolvedAttribute";
  } | {
    /**
     * @generated from field: spark.connect.Expression.UnresolvedFunction unresolved_function = 3;
     */
    value: Expression_UnresolvedFunction;
    case: "unresolvedFunction";
  } | {
    /**
     * @generated from field: spark.connect.Expression.ExpressionString expression_string = 4;
     */
    value: Expression_ExpressionString;
    case: "expressionString";
  } | {
    /**
     * @generated from field: spark.connect.Expression.UnresolvedStar unresolved_star = 5;
     */
    value: Expression_UnresolvedStar;
    case: "unresolvedStar";
  } | {
    /**
     * @generated from field: spark.connect.Expression.Alias alias = 6;
     */
    value: Expression_Alias;
    case: "alias";
  } | {
    /**
     * @generated from field: spark.connect.Expression.Cast cast = 7;
     */
    value: Expression_Cast;
    case: "cast";
  } | {
    /**
     * @generated from field: spark.connect.Expression.UnresolvedRegex unresolved_regex = 8;
     */
    value: Expression_UnresolvedRegex;
    case: "unresolvedRegex";
  } | {
    /**
     * @generated from field: spark.connect.Expression.SortOrder sort_order = 9;
     */
    value: Expression_SortOrder;
    case: "sortOrder";
  } | {
    /**
     * @generated from field: spark.connect.Expression.LambdaFunction lambda_function = 10;
     */
    value: Expression_LambdaFunction;
    case: "lambdaFunction";
  } | {
    /**
     * @generated from field: spark.connect.Expression.Window window = 11;
     */
    value: Expression_Window;
    case: "window";
  } | {
    /**
     * @generated from field: spark.connect.Expression.UnresolvedExtractValue unresolved_extract_value = 12;
     */
    value: Expression_UnresolvedExtractValue;
    case: "unresolvedExtractValue";
  } | {
    /**
     * @generated from field: spark.connect.Expression.UpdateFields update_fields = 13;
     */
    value: Expression_UpdateFields;
    case: "updateFields";
  } | {
    /**
     * @generated from field: spark.connect.Expression.UnresolvedNamedLambdaVariable unresolved_named_lambda_variable = 14;
     */
    value: Expression_UnresolvedNamedLambdaVariable;
    case: "unresolvedNamedLambdaVariable";
  } | {
    /**
     * @generated from field: spark.connect.CommonInlineUserDefinedFunction common_inline_user_defined_function = 15;
     */
    value: CommonInlineUserDefinedFunction;
    case: "commonInlineUserDefinedFunction";
  } | {
    /**
     * @generated from field: spark.connect.CallFunction call_function = 16;
     */
    value: CallFunction;
    case: "callFunction";
  } | {
    /**
     * @generated from field: spark.connect.NamedArgumentExpression named_argument_expression = 17;
     */
    value: NamedArgumentExpression;
    case: "namedArgumentExpression";
  } | {
    /**
     * @generated from field: spark.connect.MergeAction merge_action = 19;
     */
    value: MergeAction;
    case: "mergeAction";
  } | {
    /**
     * @generated from field: spark.connect.TypedAggregateExpression typed_aggregate_expression = 20;
     */
    value: TypedAggregateExpression;
    case: "typedAggregateExpression";
  } | {
    /**
     * This field is used to mark extensions to the protocol. When plugins generate arbitrary
     * relations they can add them here. During the planning the correct resolution is done.
     *
     * @generated from field: google.protobuf.Any extension = 999;
     */
    value: Any;
    case: "extension";
  } | { case: undefined; value?: undefined };
};

/**
 * Describes the message spark.connect.Expression.
 * Use `create(ExpressionSchema)` to create a new message.
 */
export const ExpressionSchema: GenMessage<Expression> = /*@__PURE__*/
  messageDesc(file_spark_connect_expressions, 0);

/**
 * Expression for the OVER clause or WINDOW clause.
 *
 * @generated from message spark.connect.Expression.Window
 */
export type Expression_Window = Message<"spark.connect.Expression.Window"> & {
  /**
   * (Required) The window function.
   *
   * @generated from field: spark.connect.Expression window_function = 1;
   */
  windowFunction?: Expression;

  /**
   * (Optional) The way that input rows are partitioned.
   *
   * @generated from field: repeated spark.connect.Expression partition_spec = 2;
   */
  partitionSpec: Expression[];

  /**
   * (Optional) Ordering of rows in a partition.
   *
   * @generated from field: repeated spark.connect.Expression.SortOrder order_spec = 3;
   */
  orderSpec: Expression_SortOrder[];

  /**
   * (Optional) Window frame in a partition.
   *
   * If not set, it will be treated as 'UnspecifiedFrame'.
   *
   * @generated from field: spark.connect.Expression.Window.WindowFrame frame_spec = 4;
   */
  frameSpec?: Expression_Window_WindowFrame;
};

/**
 * Describes the message spark.connect.Expression.Window.
 * Use `create(Expression_WindowSchema)` to create a new message.
 */
export const Expression_WindowSchema: GenMessage<Expression_Window> = /*@__PURE__*/
  messageDesc(file_spark_connect_expressions, 0, 0);

/**
 * The window frame
 *
 * @generated from message spark.connect.Expression.Window.WindowFrame
 */
export type Expression_Window_WindowFrame = Message<"spark.connect.Expression.Window.WindowFrame"> & {
  /**
   * (Required) The type of the frame.
   *
   * @generated from field: spark.connect.Expression.Window.WindowFrame.FrameType frame_type = 1;
   */
  frameType: Expression_Window_WindowFrame_FrameType;

  /**
   * (Required) The lower bound of the frame.
   *
   * @generated from field: spark.connect.Expression.Window.WindowFrame.FrameBoundary lower = 2;
   */
  lower?: Expression_Window_WindowFrame_FrameBoundary;

  /**
   * (Required) The upper bound of the frame.
   *
   * @generated from field: spark.connect.Expression.Window.WindowFrame.FrameBoundary upper = 3;
   */
  upper?: Expression_Window_WindowFrame_FrameBoundary;
};

/**
 * Describes the message spark.connect.Expression.Window.WindowFrame.
 * Use `create(Expression_Window_WindowFrameSchema)` to create a new message.
 */
export const Expression_Window_WindowFrameSchema: GenMessage<Expression_Window_WindowFrame> = /*@__PURE__*/
  messageDesc(file_spark_connect_expressions, 0, 0, 0);

/**
 * @generated from message spark.connect.Expression.Window.WindowFrame.FrameBoundary
 */
export type Expression_Window_WindowFrame_FrameBoundary = Message<"spark.connect.Expression.Window.WindowFrame.FrameBoundary"> & {
  /**
   * @generated from oneof spark.connect.Expression.Window.WindowFrame.FrameBoundary.boundary
   */
  boundary: {
    /**
     * CURRENT ROW boundary
     *
     * @generated from field: bool current_row = 1;
     */
    value: boolean;
    case: "currentRow";
  } | {
    /**
     * UNBOUNDED boundary.
     * For lower bound, it will be converted to 'UnboundedPreceding'.
     * for upper bound, it will be converted to 'UnboundedFollowing'.
     *
     * @generated from field: bool unbounded = 2;
     */
    value: boolean;
    case: "unbounded";
  } | {
    /**
     * This is an expression for future proofing. We are expecting literals on the server side.
     *
     * @generated from field: spark.connect.Expression value = 3;
     */
    value: Expression;
    case: "value";
  } | { case: undefined; value?: undefined };
};

/**
 * Describes the message spark.connect.Expression.Window.WindowFrame.FrameBoundary.
 * Use `create(Expression_Window_WindowFrame_FrameBoundarySchema)` to create a new message.
 */
export const Expression_Window_WindowFrame_FrameBoundarySchema: GenMessage<Expression_Window_WindowFrame_FrameBoundary> = /*@__PURE__*/
  messageDesc(file_spark_connect_expressions, 0, 0, 0, 0);

/**
 * @generated from enum spark.connect.Expression.Window.WindowFrame.FrameType
 */
export enum Expression_Window_WindowFrame_FrameType {
  /**
   * @generated from enum value: FRAME_TYPE_UNDEFINED = 0;
   */
  UNDEFINED = 0,

  /**
   * RowFrame treats rows in a partition individually.
   *
   * @generated from enum value: FRAME_TYPE_ROW = 1;
   */
  ROW = 1,

  /**
   * RangeFrame treats rows in a partition as groups of peers.
   * All rows having the same 'ORDER BY' ordering are considered as peers.
   *
   * @generated from enum value: FRAME_TYPE_RANGE = 2;
   */
  RANGE = 2,
}

/**
 * Describes the enum spark.connect.Expression.Window.WindowFrame.FrameType.
 */
export const Expression_Window_WindowFrame_FrameTypeSchema: GenEnum<Expression_Window_WindowFrame_FrameType> = /*@__PURE__*/
  enumDesc(file_spark_connect_expressions, 0, 0, 0, 0);

/**
 * SortOrder is used to specify the  data ordering, it is normally used in Sort and Window.
 * It is an unevaluable expression and cannot be evaluated, so can not be used in Projection.
 *
 * @generated from message spark.connect.Expression.SortOrder
 */
export type Expression_SortOrder = Message<"spark.connect.Expression.SortOrder"> & {
  /**
   * (Required) The expression to be sorted.
   *
   * @generated from field: spark.connect.Expression child = 1;
   */
  child?: Expression;

  /**
   * (Required) The sort direction, should be ASCENDING or DESCENDING.
   *
   * @generated from field: spark.connect.Expression.SortOrder.SortDirection direction = 2;
   */
  direction: Expression_SortOrder_SortDirection;

  /**
   * (Required) How to deal with NULLs, should be NULLS_FIRST or NULLS_LAST.
   *
   * @generated from field: spark.connect.Expression.SortOrder.NullOrdering null_ordering = 3;
   */
  nullOrdering: Expression_SortOrder_NullOrdering;
};

/**
 * Describes the message spark.connect.Expression.SortOrder.
 * Use `create(Expression_SortOrderSchema)` to create a new message.
 */
export const Expression_SortOrderSchema: GenMessage<Expression_SortOrder> = /*@__PURE__*/
  messageDesc(file_spark_connect_expressions, 0, 1);

/**
 * @generated from enum spark.connect.Expression.SortOrder.SortDirection
 */
export enum Expression_SortOrder_SortDirection {
  /**
   * @generated from enum value: SORT_DIRECTION_UNSPECIFIED = 0;
   */
  UNSPECIFIED = 0,

  /**
   * @generated from enum value: SORT_DIRECTION_ASCENDING = 1;
   */
  ASCENDING = 1,

  /**
   * @generated from enum value: SORT_DIRECTION_DESCENDING = 2;
   */
  DESCENDING = 2,
}

/**
 * Describes the enum spark.connect.Expression.SortOrder.SortDirection.
 */
export const Expression_SortOrder_SortDirectionSchema: GenEnum<Expression_SortOrder_SortDirection> = /*@__PURE__*/
  enumDesc(file_spark_connect_expressions, 0, 1, 0);

/**
 * @generated from enum spark.connect.Expression.SortOrder.NullOrdering
 */
export enum Expression_SortOrder_NullOrdering {
  /**
   * @generated from enum value: SORT_NULLS_UNSPECIFIED = 0;
   */
  SORT_NULLS_UNSPECIFIED = 0,

  /**
   * @generated from enum value: SORT_NULLS_FIRST = 1;
   */
  SORT_NULLS_FIRST = 1,

  /**
   * @generated from enum value: SORT_NULLS_LAST = 2;
   */
  SORT_NULLS_LAST = 2,
}

/**
 * Describes the enum spark.connect.Expression.SortOrder.NullOrdering.
 */
export const Expression_SortOrder_NullOrderingSchema: GenEnum<Expression_SortOrder_NullOrdering> = /*@__PURE__*/
  enumDesc(file_spark_connect_expressions, 0, 1, 1);

/**
 * @generated from message spark.connect.Expression.Cast
 */
export type Expression_Cast = Message<"spark.connect.Expression.Cast"> & {
  /**
   * (Required) the expression to be casted.
   *
   * @generated from field: spark.connect.Expression expr = 1;
   */
  expr?: Expression;

  /**
   * (Required) the data type that the expr to be casted to.
   *
   * @generated from oneof spark.connect.Expression.Cast.cast_to_type
   */
  castToType: {
    /**
     * @generated from field: spark.connect.DataType type = 2;
     */
    value: DataType;
    case: "type";
  } | {
    /**
     * If this is set, Server will use Catalyst parser to parse this string to DataType.
     *
     * @generated from field: string type_str = 3;
     */
    value: string;
    case: "typeStr";
  } | { case: undefined; value?: undefined };

  /**
   * (Optional) The expression evaluation mode.
   *
   * @generated from field: spark.connect.Expression.Cast.EvalMode eval_mode = 4;
   */
  evalMode: Expression_Cast_EvalMode;
};

/**
 * Describes the message spark.connect.Expression.Cast.
 * Use `create(Expression_CastSchema)` to create a new message.
 */
export const Expression_CastSchema: GenMessage<Expression_Cast> = /*@__PURE__*/
  messageDesc(file_spark_connect_expressions, 0, 2);

/**
 * @generated from enum spark.connect.Expression.Cast.EvalMode
 */
export enum Expression_Cast_EvalMode {
  /**
   * @generated from enum value: EVAL_MODE_UNSPECIFIED = 0;
   */
  UNSPECIFIED = 0,

  /**
   * @generated from enum value: EVAL_MODE_LEGACY = 1;
   */
  LEGACY = 1,

  /**
   * @generated from enum value: EVAL_MODE_ANSI = 2;
   */
  ANSI = 2,

  /**
   * @generated from enum value: EVAL_MODE_TRY = 3;
   */
  TRY = 3,
}

/**
 * Describes the enum spark.connect.Expression.Cast.EvalMode.
 */
export const Expression_Cast_EvalModeSchema: GenEnum<Expression_Cast_EvalMode> = /*@__PURE__*/
  enumDesc(file_spark_connect_expressions, 0, 2, 0);

/**
 * @generated from message spark.connect.Expression.Literal
 */
export type Expression_Literal = Message<"spark.connect.Expression.Literal"> & {
  /**
   * @generated from oneof spark.connect.Expression.Literal.literal_type
   */
  literalType: {
    /**
     * @generated from field: spark.connect.DataType null = 1;
     */
    value: DataType;
    case: "null";
  } | {
    /**
     * @generated from field: bytes binary = 2;
     */
    value: Uint8Array;
    case: "binary";
  } | {
    /**
     * @generated from field: bool boolean = 3;
     */
    value: boolean;
    case: "boolean";
  } | {
    /**
     * @generated from field: int32 byte = 4;
     */
    value: number;
    case: "byte";
  } | {
    /**
     * @generated from field: int32 short = 5;
     */
    value: number;
    case: "short";
  } | {
    /**
     * @generated from field: int32 integer = 6;
     */
    value: number;
    case: "integer";
  } | {
    /**
     * @generated from field: int64 long = 7;
     */
    value: bigint;
    case: "long";
  } | {
    /**
     * @generated from field: float float = 10;
     */
    value: number;
    case: "float";
  } | {
    /**
     * @generated from field: double double = 11;
     */
    value: number;
    case: "double";
  } | {
    /**
     * @generated from field: spark.connect.Expression.Literal.Decimal decimal = 12;
     */
    value: Expression_Literal_Decimal;
    case: "decimal";
  } | {
    /**
     * @generated from field: string string = 13;
     */
    value: string;
    case: "string";
  } | {
    /**
     * Date in units of days since the UNIX epoch.
     *
     * @generated from field: int32 date = 16;
     */
    value: number;
    case: "date";
  } | {
    /**
     * Timestamp in units of microseconds since the UNIX epoch.
     *
     * @generated from field: int64 timestamp = 17;
     */
    value: bigint;
    case: "timestamp";
  } | {
    /**
     * Timestamp in units of microseconds since the UNIX epoch (without timezone information).
     *
     * @generated from field: int64 timestamp_ntz = 18;
     */
    value: bigint;
    case: "timestampNtz";
  } | {
    /**
     * @generated from field: spark.connect.Expression.Literal.CalendarInterval calendar_interval = 19;
     */
    value: Expression_Literal_CalendarInterval;
    case: "calendarInterval";
  } | {
    /**
     * @generated from field: int32 year_month_interval = 20;
     */
    value: number;
    case: "yearMonthInterval";
  } | {
    /**
     * @generated from field: int64 day_time_interval = 21;
     */
    value: bigint;
    case: "dayTimeInterval";
  } | {
    /**
     * @generated from field: spark.connect.Expression.Literal.Array array = 22;
     */
    value: Expression_Literal_Array;
    case: "array";
  } | {
    /**
     * @generated from field: spark.connect.Expression.Literal.Map map = 23;
     */
    value: Expression_Literal_Map;
    case: "map";
  } | {
    /**
     * @generated from field: spark.connect.Expression.Literal.Struct struct = 24;
     */
    value: Expression_Literal_Struct;
    case: "struct";
  } | { case: undefined; value?: undefined };
};

/**
 * Describes the message spark.connect.Expression.Literal.
 * Use `create(Expression_LiteralSchema)` to create a new message.
 */
export const Expression_LiteralSchema: GenMessage<Expression_Literal> = /*@__PURE__*/
  messageDesc(file_spark_connect_expressions, 0, 3);

/**
 * @generated from message spark.connect.Expression.Literal.Decimal
 */
export type Expression_Literal_Decimal = Message<"spark.connect.Expression.Literal.Decimal"> & {
  /**
   * the string representation.
   *
   * @generated from field: string value = 1;
   */
  value: string;

  /**
   * The maximum number of digits allowed in the value.
   * the maximum precision is 38.
   *
   * @generated from field: optional int32 precision = 2;
   */
  precision?: number;

  /**
   * declared scale of decimal literal
   *
   * @generated from field: optional int32 scale = 3;
   */
  scale?: number;
};

/**
 * Describes the message spark.connect.Expression.Literal.Decimal.
 * Use `create(Expression_Literal_DecimalSchema)` to create a new message.
 */
export const Expression_Literal_DecimalSchema: GenMessage<Expression_Literal_Decimal> = /*@__PURE__*/
  messageDesc(file_spark_connect_expressions, 0, 3, 0);

/**
 * @generated from message spark.connect.Expression.Literal.CalendarInterval
 */
export type Expression_Literal_CalendarInterval = Message<"spark.connect.Expression.Literal.CalendarInterval"> & {
  /**
   * @generated from field: int32 months = 1;
   */
  months: number;

  /**
   * @generated from field: int32 days = 2;
   */
  days: number;

  /**
   * @generated from field: int64 microseconds = 3;
   */
  microseconds: bigint;
};

/**
 * Describes the message spark.connect.Expression.Literal.CalendarInterval.
 * Use `create(Expression_Literal_CalendarIntervalSchema)` to create a new message.
 */
export const Expression_Literal_CalendarIntervalSchema: GenMessage<Expression_Literal_CalendarInterval> = /*@__PURE__*/
  messageDesc(file_spark_connect_expressions, 0, 3, 1);

/**
 * @generated from message spark.connect.Expression.Literal.Array
 */
export type Expression_Literal_Array = Message<"spark.connect.Expression.Literal.Array"> & {
  /**
   * @generated from field: spark.connect.DataType element_type = 1;
   */
  elementType?: DataType;

  /**
   * @generated from field: repeated spark.connect.Expression.Literal elements = 2;
   */
  elements: Expression_Literal[];
};

/**
 * Describes the message spark.connect.Expression.Literal.Array.
 * Use `create(Expression_Literal_ArraySchema)` to create a new message.
 */
export const Expression_Literal_ArraySchema: GenMessage<Expression_Literal_Array> = /*@__PURE__*/
  messageDesc(file_spark_connect_expressions, 0, 3, 2);

/**
 * @generated from message spark.connect.Expression.Literal.Map
 */
export type Expression_Literal_Map = Message<"spark.connect.Expression.Literal.Map"> & {
  /**
   * @generated from field: spark.connect.DataType key_type = 1;
   */
  keyType?: DataType;

  /**
   * @generated from field: spark.connect.DataType value_type = 2;
   */
  valueType?: DataType;

  /**
   * @generated from field: repeated spark.connect.Expression.Literal keys = 3;
   */
  keys: Expression_Literal[];

  /**
   * @generated from field: repeated spark.connect.Expression.Literal values = 4;
   */
  values: Expression_Literal[];
};

/**
 * Describes the message spark.connect.Expression.Literal.Map.
 * Use `create(Expression_Literal_MapSchema)` to create a new message.
 */
export const Expression_Literal_MapSchema: GenMessage<Expression_Literal_Map> = /*@__PURE__*/
  messageDesc(file_spark_connect_expressions, 0, 3, 3);

/**
 * @generated from message spark.connect.Expression.Literal.Struct
 */
export type Expression_Literal_Struct = Message<"spark.connect.Expression.Literal.Struct"> & {
  /**
   * @generated from field: spark.connect.DataType struct_type = 1;
   */
  structType?: DataType;

  /**
   * @generated from field: repeated spark.connect.Expression.Literal elements = 2;
   */
  elements: Expression_Literal[];
};

/**
 * Describes the message spark.connect.Expression.Literal.Struct.
 * Use `create(Expression_Literal_StructSchema)` to create a new message.
 */
export const Expression_Literal_StructSchema: GenMessage<Expression_Literal_Struct> = /*@__PURE__*/
  messageDesc(file_spark_connect_expressions, 0, 3, 4);

/**
 * An unresolved attribute that is not explicitly bound to a specific column, but the column
 * is resolved during analysis by name.
 *
 * @generated from message spark.connect.Expression.UnresolvedAttribute
 */
export type Expression_UnresolvedAttribute = Message<"spark.connect.Expression.UnresolvedAttribute"> & {
  /**
   * (Required) An identifier that will be parsed by Catalyst parser. This should follow the
   * Spark SQL identifier syntax.
   *
   * @generated from field: string unparsed_identifier = 1;
   */
  unparsedIdentifier: string;

  /**
   * (Optional) The id of corresponding connect plan.
   *
   * @generated from field: optional int64 plan_id = 2;
   */
  planId?: bigint;

  /**
   * (Optional) The requested column is a metadata column.
   *
   * @generated from field: optional bool is_metadata_column = 3;
   */
  isMetadataColumn?: boolean;
};

/**
 * Describes the message spark.connect.Expression.UnresolvedAttribute.
 * Use `create(Expression_UnresolvedAttributeSchema)` to create a new message.
 */
export const Expression_UnresolvedAttributeSchema: GenMessage<Expression_UnresolvedAttribute> = /*@__PURE__*/
  messageDesc(file_spark_connect_expressions, 0, 4);

/**
 * An unresolved function is not explicitly bound to one explicit function, but the function
 * is resolved during analysis following Sparks name resolution rules.
 *
 * @generated from message spark.connect.Expression.UnresolvedFunction
 */
export type Expression_UnresolvedFunction = Message<"spark.connect.Expression.UnresolvedFunction"> & {
  /**
   * (Required) name (or unparsed name for user defined function) for the unresolved function.
   *
   * @generated from field: string function_name = 1;
   */
  functionName: string;

  /**
   * (Optional) Function arguments. Empty arguments are allowed.
   *
   * @generated from field: repeated spark.connect.Expression arguments = 2;
   */
  arguments: Expression[];

  /**
   * (Required) Indicate if this function should be applied on distinct values.
   *
   * @generated from field: bool is_distinct = 3;
   */
  isDistinct: boolean;

  /**
   * (Required) Indicate if this is a user defined function.
   *
   * When it is not a user defined function, Connect will use the function name directly.
   * When it is a user defined function, Connect will parse the function name first.
   *
   * @generated from field: bool is_user_defined_function = 4;
   */
  isUserDefinedFunction: boolean;
};

/**
 * Describes the message spark.connect.Expression.UnresolvedFunction.
 * Use `create(Expression_UnresolvedFunctionSchema)` to create a new message.
 */
export const Expression_UnresolvedFunctionSchema: GenMessage<Expression_UnresolvedFunction> = /*@__PURE__*/
  messageDesc(file_spark_connect_expressions, 0, 5);

/**
 * Expression as string.
 *
 * @generated from message spark.connect.Expression.ExpressionString
 */
export type Expression_ExpressionString = Message<"spark.connect.Expression.ExpressionString"> & {
  /**
   * (Required) A SQL expression that will be parsed by Catalyst parser.
   *
   * @generated from field: string expression = 1;
   */
  expression: string;
};

/**
 * Describes the message spark.connect.Expression.ExpressionString.
 * Use `create(Expression_ExpressionStringSchema)` to create a new message.
 */
export const Expression_ExpressionStringSchema: GenMessage<Expression_ExpressionString> = /*@__PURE__*/
  messageDesc(file_spark_connect_expressions, 0, 6);

/**
 * UnresolvedStar is used to expand all the fields of a relation or struct.
 *
 * @generated from message spark.connect.Expression.UnresolvedStar
 */
export type Expression_UnresolvedStar = Message<"spark.connect.Expression.UnresolvedStar"> & {
  /**
   * (Optional) The target of the expansion.
   *
   * If set, it should end with '.*' and will be parsed by 'parseAttributeName'
   * in the server side.
   *
   * @generated from field: optional string unparsed_target = 1;
   */
  unparsedTarget?: string;

  /**
   * (Optional) The id of corresponding connect plan.
   *
   * @generated from field: optional int64 plan_id = 2;
   */
  planId?: bigint;
};

/**
 * Describes the message spark.connect.Expression.UnresolvedStar.
 * Use `create(Expression_UnresolvedStarSchema)` to create a new message.
 */
export const Expression_UnresolvedStarSchema: GenMessage<Expression_UnresolvedStar> = /*@__PURE__*/
  messageDesc(file_spark_connect_expressions, 0, 7);

/**
 * Represents all of the input attributes to a given relational operator, for example in
 * "SELECT `(id)?+.+` FROM ...".
 *
 * @generated from message spark.connect.Expression.UnresolvedRegex
 */
export type Expression_UnresolvedRegex = Message<"spark.connect.Expression.UnresolvedRegex"> & {
  /**
   * (Required) The column name used to extract column with regex.
   *
   * @generated from field: string col_name = 1;
   */
  colName: string;

  /**
   * (Optional) The id of corresponding connect plan.
   *
   * @generated from field: optional int64 plan_id = 2;
   */
  planId?: bigint;
};

/**
 * Describes the message spark.connect.Expression.UnresolvedRegex.
 * Use `create(Expression_UnresolvedRegexSchema)` to create a new message.
 */
export const Expression_UnresolvedRegexSchema: GenMessage<Expression_UnresolvedRegex> = /*@__PURE__*/
  messageDesc(file_spark_connect_expressions, 0, 8);

/**
 * Extracts a value or values from an Expression
 *
 * @generated from message spark.connect.Expression.UnresolvedExtractValue
 */
export type Expression_UnresolvedExtractValue = Message<"spark.connect.Expression.UnresolvedExtractValue"> & {
  /**
   * (Required) The expression to extract value from, can be
   * Map, Array, Struct or array of Structs.
   *
   * @generated from field: spark.connect.Expression child = 1;
   */
  child?: Expression;

  /**
   * (Required) The expression to describe the extraction, can be
   * key of Map, index of Array, field name of Struct.
   *
   * @generated from field: spark.connect.Expression extraction = 2;
   */
  extraction?: Expression;
};

/**
 * Describes the message spark.connect.Expression.UnresolvedExtractValue.
 * Use `create(Expression_UnresolvedExtractValueSchema)` to create a new message.
 */
export const Expression_UnresolvedExtractValueSchema: GenMessage<Expression_UnresolvedExtractValue> = /*@__PURE__*/
  messageDesc(file_spark_connect_expressions, 0, 9);

/**
 * Add, replace or drop a field of `StructType` expression by name.
 *
 * @generated from message spark.connect.Expression.UpdateFields
 */
export type Expression_UpdateFields = Message<"spark.connect.Expression.UpdateFields"> & {
  /**
   * (Required) The struct expression.
   *
   * @generated from field: spark.connect.Expression struct_expression = 1;
   */
  structExpression?: Expression;

  /**
   * (Required) The field name.
   *
   * @generated from field: string field_name = 2;
   */
  fieldName: string;

  /**
   * (Optional) The expression to add or replace.
   *
   * When not set, it means this field will be dropped.
   *
   * @generated from field: spark.connect.Expression value_expression = 3;
   */
  valueExpression?: Expression;
};

/**
 * Describes the message spark.connect.Expression.UpdateFields.
 * Use `create(Expression_UpdateFieldsSchema)` to create a new message.
 */
export const Expression_UpdateFieldsSchema: GenMessage<Expression_UpdateFields> = /*@__PURE__*/
  messageDesc(file_spark_connect_expressions, 0, 10);

/**
 * @generated from message spark.connect.Expression.Alias
 */
export type Expression_Alias = Message<"spark.connect.Expression.Alias"> & {
  /**
   * (Required) The expression that alias will be added on.
   *
   * @generated from field: spark.connect.Expression expr = 1;
   */
  expr?: Expression;

  /**
   * (Required) a list of name parts for the alias.
   *
   * Scalar columns only has one name that presents.
   *
   * @generated from field: repeated string name = 2;
   */
  name: string[];

  /**
   * (Optional) Alias metadata expressed as a JSON map.
   *
   * @generated from field: optional string metadata = 3;
   */
  metadata?: string;
};

/**
 * Describes the message spark.connect.Expression.Alias.
 * Use `create(Expression_AliasSchema)` to create a new message.
 */
export const Expression_AliasSchema: GenMessage<Expression_Alias> = /*@__PURE__*/
  messageDesc(file_spark_connect_expressions, 0, 11);

/**
 * @generated from message spark.connect.Expression.LambdaFunction
 */
export type Expression_LambdaFunction = Message<"spark.connect.Expression.LambdaFunction"> & {
  /**
   * (Required) The lambda function.
   *
   * The function body should use 'UnresolvedAttribute' as arguments, the sever side will
   * replace 'UnresolvedAttribute' with 'UnresolvedNamedLambdaVariable'.
   *
   * @generated from field: spark.connect.Expression function = 1;
   */
  function?: Expression;

  /**
   * (Required) Function variables. Must contains 1 ~ 3 variables.
   *
   * @generated from field: repeated spark.connect.Expression.UnresolvedNamedLambdaVariable arguments = 2;
   */
  arguments: Expression_UnresolvedNamedLambdaVariable[];
};

/**
 * Describes the message spark.connect.Expression.LambdaFunction.
 * Use `create(Expression_LambdaFunctionSchema)` to create a new message.
 */
export const Expression_LambdaFunctionSchema: GenMessage<Expression_LambdaFunction> = /*@__PURE__*/
  messageDesc(file_spark_connect_expressions, 0, 12);

/**
 * @generated from message spark.connect.Expression.UnresolvedNamedLambdaVariable
 */
export type Expression_UnresolvedNamedLambdaVariable = Message<"spark.connect.Expression.UnresolvedNamedLambdaVariable"> & {
  /**
   * (Required) a list of name parts for the variable. Must not be empty.
   *
   * @generated from field: repeated string name_parts = 1;
   */
  nameParts: string[];
};

/**
 * Describes the message spark.connect.Expression.UnresolvedNamedLambdaVariable.
 * Use `create(Expression_UnresolvedNamedLambdaVariableSchema)` to create a new message.
 */
export const Expression_UnresolvedNamedLambdaVariableSchema: GenMessage<Expression_UnresolvedNamedLambdaVariable> = /*@__PURE__*/
  messageDesc(file_spark_connect_expressions, 0, 13);

/**
 * @generated from message spark.connect.ExpressionCommon
 */
export type ExpressionCommon = Message<"spark.connect.ExpressionCommon"> & {
  /**
   * (Required) Keep the information of the origin for this expression such as stacktrace.
   *
   * @generated from field: spark.connect.Origin origin = 1;
   */
  origin?: Origin;
};

/**
 * Describes the message spark.connect.ExpressionCommon.
 * Use `create(ExpressionCommonSchema)` to create a new message.
 */
export const ExpressionCommonSchema: GenMessage<ExpressionCommon> = /*@__PURE__*/
  messageDesc(file_spark_connect_expressions, 1);

/**
 * @generated from message spark.connect.CommonInlineUserDefinedFunction
 */
export type CommonInlineUserDefinedFunction = Message<"spark.connect.CommonInlineUserDefinedFunction"> & {
  /**
   * (Required) Name of the user-defined function.
   *
   * @generated from field: string function_name = 1;
   */
  functionName: string;

  /**
   * (Optional) Indicate if the user-defined function is deterministic.
   *
   * @generated from field: bool deterministic = 2;
   */
  deterministic: boolean;

  /**
   * (Optional) Function arguments. Empty arguments are allowed.
   *
   * @generated from field: repeated spark.connect.Expression arguments = 3;
   */
  arguments: Expression[];

  /**
   * (Required) Indicate the function type of the user-defined function.
   *
   * @generated from oneof spark.connect.CommonInlineUserDefinedFunction.function
   */
  function: {
    /**
     * @generated from field: spark.connect.PythonUDF python_udf = 4;
     */
    value: PythonUDF;
    case: "pythonUdf";
  } | {
    /**
     * @generated from field: spark.connect.ScalarScalaUDF scalar_scala_udf = 5;
     */
    value: ScalarScalaUDF;
    case: "scalarScalaUdf";
  } | {
    /**
     * @generated from field: spark.connect.JavaUDF java_udf = 6;
     */
    value: JavaUDF;
    case: "javaUdf";
  } | { case: undefined; value?: undefined };
};

/**
 * Describes the message spark.connect.CommonInlineUserDefinedFunction.
 * Use `create(CommonInlineUserDefinedFunctionSchema)` to create a new message.
 */
export const CommonInlineUserDefinedFunctionSchema: GenMessage<CommonInlineUserDefinedFunction> = /*@__PURE__*/
  messageDesc(file_spark_connect_expressions, 2);

/**
 * @generated from message spark.connect.PythonUDF
 */
export type PythonUDF = Message<"spark.connect.PythonUDF"> & {
  /**
   * (Required) Output type of the Python UDF
   *
   * @generated from field: spark.connect.DataType output_type = 1;
   */
  outputType?: DataType;

  /**
   * (Required) EvalType of the Python UDF
   *
   * @generated from field: int32 eval_type = 2;
   */
  evalType: number;

  /**
   * (Required) The encoded commands of the Python UDF
   *
   * @generated from field: bytes command = 3;
   */
  command: Uint8Array;

  /**
   * (Required) Python version being used in the client.
   *
   * @generated from field: string python_ver = 4;
   */
  pythonVer: string;

  /**
   * (Optional) Additional includes for the Python UDF.
   *
   * @generated from field: repeated string additional_includes = 5;
   */
  additionalIncludes: string[];
};

/**
 * Describes the message spark.connect.PythonUDF.
 * Use `create(PythonUDFSchema)` to create a new message.
 */
export const PythonUDFSchema: GenMessage<PythonUDF> = /*@__PURE__*/
  messageDesc(file_spark_connect_expressions, 3);

/**
 * @generated from message spark.connect.ScalarScalaUDF
 */
export type ScalarScalaUDF = Message<"spark.connect.ScalarScalaUDF"> & {
  /**
   * (Required) Serialized JVM object containing UDF definition, input encoders and output encoder
   *
   * @generated from field: bytes payload = 1;
   */
  payload: Uint8Array;

  /**
   * (Optional) Input type(s) of the UDF
   *
   * @generated from field: repeated spark.connect.DataType inputTypes = 2;
   */
  inputTypes: DataType[];

  /**
   * (Required) Output type of the UDF
   *
   * @generated from field: spark.connect.DataType outputType = 3;
   */
  outputType?: DataType;

  /**
   * (Required) True if the UDF can return null value
   *
   * @generated from field: bool nullable = 4;
   */
  nullable: boolean;

  /**
   * (Required) Indicate if the UDF is an aggregate function
   *
   * @generated from field: bool aggregate = 5;
   */
  aggregate: boolean;
};

/**
 * Describes the message spark.connect.ScalarScalaUDF.
 * Use `create(ScalarScalaUDFSchema)` to create a new message.
 */
export const ScalarScalaUDFSchema: GenMessage<ScalarScalaUDF> = /*@__PURE__*/
  messageDesc(file_spark_connect_expressions, 4);

/**
 * @generated from message spark.connect.JavaUDF
 */
export type JavaUDF = Message<"spark.connect.JavaUDF"> & {
  /**
   * (Required) Fully qualified name of Java class
   *
   * @generated from field: string class_name = 1;
   */
  className: string;

  /**
   * (Optional) Output type of the Java UDF
   *
   * @generated from field: optional spark.connect.DataType output_type = 2;
   */
  outputType?: DataType;

  /**
   * (Required) Indicate if the Java user-defined function is an aggregate function
   *
   * @generated from field: bool aggregate = 3;
   */
  aggregate: boolean;
};

/**
 * Describes the message spark.connect.JavaUDF.
 * Use `create(JavaUDFSchema)` to create a new message.
 */
export const JavaUDFSchema: GenMessage<JavaUDF> = /*@__PURE__*/
  messageDesc(file_spark_connect_expressions, 5);

/**
 * @generated from message spark.connect.TypedAggregateExpression
 */
export type TypedAggregateExpression = Message<"spark.connect.TypedAggregateExpression"> & {
  /**
   * (Required) The aggregate function object packed into bytes.
   *
   * @generated from field: spark.connect.ScalarScalaUDF scalar_scala_udf = 1;
   */
  scalarScalaUdf?: ScalarScalaUDF;
};

/**
 * Describes the message spark.connect.TypedAggregateExpression.
 * Use `create(TypedAggregateExpressionSchema)` to create a new message.
 */
export const TypedAggregateExpressionSchema: GenMessage<TypedAggregateExpression> = /*@__PURE__*/
  messageDesc(file_spark_connect_expressions, 6);

/**
 * @generated from message spark.connect.CallFunction
 */
export type CallFunction = Message<"spark.connect.CallFunction"> & {
  /**
   * (Required) Unparsed name of the SQL function.
   *
   * @generated from field: string function_name = 1;
   */
  functionName: string;

  /**
   * (Optional) Function arguments. Empty arguments are allowed.
   *
   * @generated from field: repeated spark.connect.Expression arguments = 2;
   */
  arguments: Expression[];
};

/**
 * Describes the message spark.connect.CallFunction.
 * Use `create(CallFunctionSchema)` to create a new message.
 */
export const CallFunctionSchema: GenMessage<CallFunction> = /*@__PURE__*/
  messageDesc(file_spark_connect_expressions, 7);

/**
 * @generated from message spark.connect.NamedArgumentExpression
 */
export type NamedArgumentExpression = Message<"spark.connect.NamedArgumentExpression"> & {
  /**
   * (Required) The key of the named argument.
   *
   * @generated from field: string key = 1;
   */
  key: string;

  /**
   * (Required) The value expression of the named argument.
   *
   * @generated from field: spark.connect.Expression value = 2;
   */
  value?: Expression;
};

/**
 * Describes the message spark.connect.NamedArgumentExpression.
 * Use `create(NamedArgumentExpressionSchema)` to create a new message.
 */
export const NamedArgumentExpressionSchema: GenMessage<NamedArgumentExpression> = /*@__PURE__*/
  messageDesc(file_spark_connect_expressions, 8);

/**
 * @generated from message spark.connect.MergeAction
 */
export type MergeAction = Message<"spark.connect.MergeAction"> & {
  /**
   * (Required) The action type of the merge action.
   *
   * @generated from field: spark.connect.MergeAction.ActionType action_type = 1;
   */
  actionType: MergeAction_ActionType;

  /**
   * (Optional) The condition expression of the merge action.
   *
   * @generated from field: optional spark.connect.Expression condition = 2;
   */
  condition?: Expression;

  /**
   * (Optional) The assignments of the merge action. Required for ActionTypes INSERT and UPDATE.
   *
   * @generated from field: repeated spark.connect.MergeAction.Assignment assignments = 3;
   */
  assignments: MergeAction_Assignment[];
};

/**
 * Describes the message spark.connect.MergeAction.
 * Use `create(MergeActionSchema)` to create a new message.
 */
export const MergeActionSchema: GenMessage<MergeAction> = /*@__PURE__*/
  messageDesc(file_spark_connect_expressions, 9);

/**
 * @generated from message spark.connect.MergeAction.Assignment
 */
export type MergeAction_Assignment = Message<"spark.connect.MergeAction.Assignment"> & {
  /**
   * (Required) The key of the assignment.
   *
   * @generated from field: spark.connect.Expression key = 1;
   */
  key?: Expression;

  /**
   * (Required) The value of the assignment.
   *
   * @generated from field: spark.connect.Expression value = 2;
   */
  value?: Expression;
};

/**
 * Describes the message spark.connect.MergeAction.Assignment.
 * Use `create(MergeAction_AssignmentSchema)` to create a new message.
 */
export const MergeAction_AssignmentSchema: GenMessage<MergeAction_Assignment> = /*@__PURE__*/
  messageDesc(file_spark_connect_expressions, 9, 0);

/**
 * @generated from enum spark.connect.MergeAction.ActionType
 */
export enum MergeAction_ActionType {
  /**
   * @generated from enum value: ACTION_TYPE_INVALID = 0;
   */
  INVALID = 0,

  /**
   * @generated from enum value: ACTION_TYPE_DELETE = 1;
   */
  DELETE = 1,

  /**
   * @generated from enum value: ACTION_TYPE_INSERT = 2;
   */
  INSERT = 2,

  /**
   * @generated from enum value: ACTION_TYPE_INSERT_STAR = 3;
   */
  INSERT_STAR = 3,

  /**
   * @generated from enum value: ACTION_TYPE_UPDATE = 4;
   */
  UPDATE = 4,

  /**
   * @generated from enum value: ACTION_TYPE_UPDATE_STAR = 5;
   */
  UPDATE_STAR = 5,
}

/**
 * Describes the enum spark.connect.MergeAction.ActionType.
 */
export const MergeAction_ActionTypeSchema: GenEnum<MergeAction_ActionType> = /*@__PURE__*/
  enumDesc(file_spark_connect_expressions, 9, 0);

