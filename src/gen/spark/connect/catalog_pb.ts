//
// Licensed to the Apache Software Foundation (ASF) under one or more
// contributor license agreements.  See the NOTICE file distributed with
// this work for additional information regarding copyright ownership.
// The ASF licenses this file to You under the Apache License, Version 2.0
// (the "License"); you may not use this file except in compliance with
// the License.  You may obtain a copy of the License at
//
//    http://www.apache.org/licenses/LICENSE-2.0
//
// Unless required by applicable law or agreed to in writing, software
// distributed under the License is distributed on an "AS IS" BASIS,
// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
// See the License for the specific language governing permissions and
// limitations under the License.

// @generated by protoc-gen-es v2.2.3 with parameter "target=ts,import_extension=none,js_import_style=module"
// @generated from file spark/connect/catalog.proto (package spark.connect, syntax proto3)
/* eslint-disable */

import type { GenFile, GenMessage } from "@bufbuild/protobuf/codegenv1";
import { fileDesc, messageDesc } from "@bufbuild/protobuf/codegenv1";
import type { StorageLevel } from "./common_pb";
import { file_spark_connect_common } from "./common_pb";
import type { DataType } from "./types_pb";
import { file_spark_connect_types } from "./types_pb";
import type { Message } from "@bufbuild/protobuf";

/**
 * Describes the file spark/connect/catalog.proto.
 */
export const file_spark_connect_catalog: GenFile = /*@__PURE__*/
  fileDesc("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", [file_spark_connect_common, file_spark_connect_types]);

/**
 * Catalog messages are marked as unstable.
 *
 * @generated from message spark.connect.Catalog
 */
export type Catalog = Message<"spark.connect.Catalog"> & {
  /**
   * @generated from oneof spark.connect.Catalog.cat_type
   */
  catType: {
    /**
     * @generated from field: spark.connect.CurrentDatabase current_database = 1;
     */
    value: CurrentDatabase;
    case: "currentDatabase";
  } | {
    /**
     * @generated from field: spark.connect.SetCurrentDatabase set_current_database = 2;
     */
    value: SetCurrentDatabase;
    case: "setCurrentDatabase";
  } | {
    /**
     * @generated from field: spark.connect.ListDatabases list_databases = 3;
     */
    value: ListDatabases;
    case: "listDatabases";
  } | {
    /**
     * @generated from field: spark.connect.ListTables list_tables = 4;
     */
    value: ListTables;
    case: "listTables";
  } | {
    /**
     * @generated from field: spark.connect.ListFunctions list_functions = 5;
     */
    value: ListFunctions;
    case: "listFunctions";
  } | {
    /**
     * @generated from field: spark.connect.ListColumns list_columns = 6;
     */
    value: ListColumns;
    case: "listColumns";
  } | {
    /**
     * @generated from field: spark.connect.GetDatabase get_database = 7;
     */
    value: GetDatabase;
    case: "getDatabase";
  } | {
    /**
     * @generated from field: spark.connect.GetTable get_table = 8;
     */
    value: GetTable;
    case: "getTable";
  } | {
    /**
     * @generated from field: spark.connect.GetFunction get_function = 9;
     */
    value: GetFunction;
    case: "getFunction";
  } | {
    /**
     * @generated from field: spark.connect.DatabaseExists database_exists = 10;
     */
    value: DatabaseExists;
    case: "databaseExists";
  } | {
    /**
     * @generated from field: spark.connect.TableExists table_exists = 11;
     */
    value: TableExists;
    case: "tableExists";
  } | {
    /**
     * @generated from field: spark.connect.FunctionExists function_exists = 12;
     */
    value: FunctionExists;
    case: "functionExists";
  } | {
    /**
     * @generated from field: spark.connect.CreateExternalTable create_external_table = 13;
     */
    value: CreateExternalTable;
    case: "createExternalTable";
  } | {
    /**
     * @generated from field: spark.connect.CreateTable create_table = 14;
     */
    value: CreateTable;
    case: "createTable";
  } | {
    /**
     * @generated from field: spark.connect.DropTempView drop_temp_view = 15;
     */
    value: DropTempView;
    case: "dropTempView";
  } | {
    /**
     * @generated from field: spark.connect.DropGlobalTempView drop_global_temp_view = 16;
     */
    value: DropGlobalTempView;
    case: "dropGlobalTempView";
  } | {
    /**
     * @generated from field: spark.connect.RecoverPartitions recover_partitions = 17;
     */
    value: RecoverPartitions;
    case: "recoverPartitions";
  } | {
    /**
     * @generated from field: spark.connect.IsCached is_cached = 18;
     */
    value: IsCached;
    case: "isCached";
  } | {
    /**
     * @generated from field: spark.connect.CacheTable cache_table = 19;
     */
    value: CacheTable;
    case: "cacheTable";
  } | {
    /**
     * @generated from field: spark.connect.UncacheTable uncache_table = 20;
     */
    value: UncacheTable;
    case: "uncacheTable";
  } | {
    /**
     * @generated from field: spark.connect.ClearCache clear_cache = 21;
     */
    value: ClearCache;
    case: "clearCache";
  } | {
    /**
     * @generated from field: spark.connect.RefreshTable refresh_table = 22;
     */
    value: RefreshTable;
    case: "refreshTable";
  } | {
    /**
     * @generated from field: spark.connect.RefreshByPath refresh_by_path = 23;
     */
    value: RefreshByPath;
    case: "refreshByPath";
  } | {
    /**
     * @generated from field: spark.connect.CurrentCatalog current_catalog = 24;
     */
    value: CurrentCatalog;
    case: "currentCatalog";
  } | {
    /**
     * @generated from field: spark.connect.SetCurrentCatalog set_current_catalog = 25;
     */
    value: SetCurrentCatalog;
    case: "setCurrentCatalog";
  } | {
    /**
     * @generated from field: spark.connect.ListCatalogs list_catalogs = 26;
     */
    value: ListCatalogs;
    case: "listCatalogs";
  } | { case: undefined; value?: undefined };
};

/**
 * Describes the message spark.connect.Catalog.
 * Use `create(CatalogSchema)` to create a new message.
 */
export const CatalogSchema: GenMessage<Catalog> = /*@__PURE__*/
  messageDesc(file_spark_connect_catalog, 0);

/**
 * See `spark.catalog.currentDatabase`
 *
 * @generated from message spark.connect.CurrentDatabase
 */
export type CurrentDatabase = Message<"spark.connect.CurrentDatabase"> & {
};

/**
 * Describes the message spark.connect.CurrentDatabase.
 * Use `create(CurrentDatabaseSchema)` to create a new message.
 */
export const CurrentDatabaseSchema: GenMessage<CurrentDatabase> = /*@__PURE__*/
  messageDesc(file_spark_connect_catalog, 1);

/**
 * See `spark.catalog.setCurrentDatabase`
 *
 * @generated from message spark.connect.SetCurrentDatabase
 */
export type SetCurrentDatabase = Message<"spark.connect.SetCurrentDatabase"> & {
  /**
   * (Required)
   *
   * @generated from field: string db_name = 1;
   */
  dbName: string;
};

/**
 * Describes the message spark.connect.SetCurrentDatabase.
 * Use `create(SetCurrentDatabaseSchema)` to create a new message.
 */
export const SetCurrentDatabaseSchema: GenMessage<SetCurrentDatabase> = /*@__PURE__*/
  messageDesc(file_spark_connect_catalog, 2);

/**
 * See `spark.catalog.listDatabases`
 *
 * @generated from message spark.connect.ListDatabases
 */
export type ListDatabases = Message<"spark.connect.ListDatabases"> & {
  /**
   * (Optional) The pattern that the database name needs to match
   *
   * @generated from field: optional string pattern = 1;
   */
  pattern?: string;
};

/**
 * Describes the message spark.connect.ListDatabases.
 * Use `create(ListDatabasesSchema)` to create a new message.
 */
export const ListDatabasesSchema: GenMessage<ListDatabases> = /*@__PURE__*/
  messageDesc(file_spark_connect_catalog, 3);

/**
 * See `spark.catalog.listTables`
 *
 * @generated from message spark.connect.ListTables
 */
export type ListTables = Message<"spark.connect.ListTables"> & {
  /**
   * (Optional)
   *
   * @generated from field: optional string db_name = 1;
   */
  dbName?: string;

  /**
   * (Optional) The pattern that the table name needs to match
   *
   * @generated from field: optional string pattern = 2;
   */
  pattern?: string;
};

/**
 * Describes the message spark.connect.ListTables.
 * Use `create(ListTablesSchema)` to create a new message.
 */
export const ListTablesSchema: GenMessage<ListTables> = /*@__PURE__*/
  messageDesc(file_spark_connect_catalog, 4);

/**
 * See `spark.catalog.listFunctions`
 *
 * @generated from message spark.connect.ListFunctions
 */
export type ListFunctions = Message<"spark.connect.ListFunctions"> & {
  /**
   * (Optional)
   *
   * @generated from field: optional string db_name = 1;
   */
  dbName?: string;

  /**
   * (Optional) The pattern that the function name needs to match
   *
   * @generated from field: optional string pattern = 2;
   */
  pattern?: string;
};

/**
 * Describes the message spark.connect.ListFunctions.
 * Use `create(ListFunctionsSchema)` to create a new message.
 */
export const ListFunctionsSchema: GenMessage<ListFunctions> = /*@__PURE__*/
  messageDesc(file_spark_connect_catalog, 5);

/**
 * See `spark.catalog.listColumns`
 *
 * @generated from message spark.connect.ListColumns
 */
export type ListColumns = Message<"spark.connect.ListColumns"> & {
  /**
   * (Required)
   *
   * @generated from field: string table_name = 1;
   */
  tableName: string;

  /**
   * (Optional)
   *
   * @generated from field: optional string db_name = 2;
   */
  dbName?: string;
};

/**
 * Describes the message spark.connect.ListColumns.
 * Use `create(ListColumnsSchema)` to create a new message.
 */
export const ListColumnsSchema: GenMessage<ListColumns> = /*@__PURE__*/
  messageDesc(file_spark_connect_catalog, 6);

/**
 * See `spark.catalog.getDatabase`
 *
 * @generated from message spark.connect.GetDatabase
 */
export type GetDatabase = Message<"spark.connect.GetDatabase"> & {
  /**
   * (Required)
   *
   * @generated from field: string db_name = 1;
   */
  dbName: string;
};

/**
 * Describes the message spark.connect.GetDatabase.
 * Use `create(GetDatabaseSchema)` to create a new message.
 */
export const GetDatabaseSchema: GenMessage<GetDatabase> = /*@__PURE__*/
  messageDesc(file_spark_connect_catalog, 7);

/**
 * See `spark.catalog.getTable`
 *
 * @generated from message spark.connect.GetTable
 */
export type GetTable = Message<"spark.connect.GetTable"> & {
  /**
   * (Required)
   *
   * @generated from field: string table_name = 1;
   */
  tableName: string;

  /**
   * (Optional)
   *
   * @generated from field: optional string db_name = 2;
   */
  dbName?: string;
};

/**
 * Describes the message spark.connect.GetTable.
 * Use `create(GetTableSchema)` to create a new message.
 */
export const GetTableSchema: GenMessage<GetTable> = /*@__PURE__*/
  messageDesc(file_spark_connect_catalog, 8);

/**
 * See `spark.catalog.getFunction`
 *
 * @generated from message spark.connect.GetFunction
 */
export type GetFunction = Message<"spark.connect.GetFunction"> & {
  /**
   * (Required)
   *
   * @generated from field: string function_name = 1;
   */
  functionName: string;

  /**
   * (Optional)
   *
   * @generated from field: optional string db_name = 2;
   */
  dbName?: string;
};

/**
 * Describes the message spark.connect.GetFunction.
 * Use `create(GetFunctionSchema)` to create a new message.
 */
export const GetFunctionSchema: GenMessage<GetFunction> = /*@__PURE__*/
  messageDesc(file_spark_connect_catalog, 9);

/**
 * See `spark.catalog.databaseExists`
 *
 * @generated from message spark.connect.DatabaseExists
 */
export type DatabaseExists = Message<"spark.connect.DatabaseExists"> & {
  /**
   * (Required)
   *
   * @generated from field: string db_name = 1;
   */
  dbName: string;
};

/**
 * Describes the message spark.connect.DatabaseExists.
 * Use `create(DatabaseExistsSchema)` to create a new message.
 */
export const DatabaseExistsSchema: GenMessage<DatabaseExists> = /*@__PURE__*/
  messageDesc(file_spark_connect_catalog, 10);

/**
 * See `spark.catalog.tableExists`
 *
 * @generated from message spark.connect.TableExists
 */
export type TableExists = Message<"spark.connect.TableExists"> & {
  /**
   * (Required)
   *
   * @generated from field: string table_name = 1;
   */
  tableName: string;

  /**
   * (Optional)
   *
   * @generated from field: optional string db_name = 2;
   */
  dbName?: string;
};

/**
 * Describes the message spark.connect.TableExists.
 * Use `create(TableExistsSchema)` to create a new message.
 */
export const TableExistsSchema: GenMessage<TableExists> = /*@__PURE__*/
  messageDesc(file_spark_connect_catalog, 11);

/**
 * See `spark.catalog.functionExists`
 *
 * @generated from message spark.connect.FunctionExists
 */
export type FunctionExists = Message<"spark.connect.FunctionExists"> & {
  /**
   * (Required)
   *
   * @generated from field: string function_name = 1;
   */
  functionName: string;

  /**
   * (Optional)
   *
   * @generated from field: optional string db_name = 2;
   */
  dbName?: string;
};

/**
 * Describes the message spark.connect.FunctionExists.
 * Use `create(FunctionExistsSchema)` to create a new message.
 */
export const FunctionExistsSchema: GenMessage<FunctionExists> = /*@__PURE__*/
  messageDesc(file_spark_connect_catalog, 12);

/**
 * See `spark.catalog.createExternalTable`
 *
 * @generated from message spark.connect.CreateExternalTable
 */
export type CreateExternalTable = Message<"spark.connect.CreateExternalTable"> & {
  /**
   * (Required)
   *
   * @generated from field: string table_name = 1;
   */
  tableName: string;

  /**
   * (Optional)
   *
   * @generated from field: optional string path = 2;
   */
  path?: string;

  /**
   * (Optional)
   *
   * @generated from field: optional string source = 3;
   */
  source?: string;

  /**
   * (Optional)
   *
   * @generated from field: optional spark.connect.DataType schema = 4;
   */
  schema?: DataType;

  /**
   * Options could be empty for valid data source format.
   * The map key is case insensitive.
   *
   * @generated from field: map<string, string> options = 5;
   */
  options: { [key: string]: string };
};

/**
 * Describes the message spark.connect.CreateExternalTable.
 * Use `create(CreateExternalTableSchema)` to create a new message.
 */
export const CreateExternalTableSchema: GenMessage<CreateExternalTable> = /*@__PURE__*/
  messageDesc(file_spark_connect_catalog, 13);

/**
 * See `spark.catalog.createTable`
 *
 * @generated from message spark.connect.CreateTable
 */
export type CreateTable = Message<"spark.connect.CreateTable"> & {
  /**
   * (Required)
   *
   * @generated from field: string table_name = 1;
   */
  tableName: string;

  /**
   * (Optional)
   *
   * @generated from field: optional string path = 2;
   */
  path?: string;

  /**
   * (Optional)
   *
   * @generated from field: optional string source = 3;
   */
  source?: string;

  /**
   * (Optional)
   *
   * @generated from field: optional string description = 4;
   */
  description?: string;

  /**
   * (Optional)
   *
   * @generated from field: optional spark.connect.DataType schema = 5;
   */
  schema?: DataType;

  /**
   * Options could be empty for valid data source format.
   * The map key is case insensitive.
   *
   * @generated from field: map<string, string> options = 6;
   */
  options: { [key: string]: string };
};

/**
 * Describes the message spark.connect.CreateTable.
 * Use `create(CreateTableSchema)` to create a new message.
 */
export const CreateTableSchema: GenMessage<CreateTable> = /*@__PURE__*/
  messageDesc(file_spark_connect_catalog, 14);

/**
 * See `spark.catalog.dropTempView`
 *
 * @generated from message spark.connect.DropTempView
 */
export type DropTempView = Message<"spark.connect.DropTempView"> & {
  /**
   * (Required)
   *
   * @generated from field: string view_name = 1;
   */
  viewName: string;
};

/**
 * Describes the message spark.connect.DropTempView.
 * Use `create(DropTempViewSchema)` to create a new message.
 */
export const DropTempViewSchema: GenMessage<DropTempView> = /*@__PURE__*/
  messageDesc(file_spark_connect_catalog, 15);

/**
 * See `spark.catalog.dropGlobalTempView`
 *
 * @generated from message spark.connect.DropGlobalTempView
 */
export type DropGlobalTempView = Message<"spark.connect.DropGlobalTempView"> & {
  /**
   * (Required)
   *
   * @generated from field: string view_name = 1;
   */
  viewName: string;
};

/**
 * Describes the message spark.connect.DropGlobalTempView.
 * Use `create(DropGlobalTempViewSchema)` to create a new message.
 */
export const DropGlobalTempViewSchema: GenMessage<DropGlobalTempView> = /*@__PURE__*/
  messageDesc(file_spark_connect_catalog, 16);

/**
 * See `spark.catalog.recoverPartitions`
 *
 * @generated from message spark.connect.RecoverPartitions
 */
export type RecoverPartitions = Message<"spark.connect.RecoverPartitions"> & {
  /**
   * (Required)
   *
   * @generated from field: string table_name = 1;
   */
  tableName: string;
};

/**
 * Describes the message spark.connect.RecoverPartitions.
 * Use `create(RecoverPartitionsSchema)` to create a new message.
 */
export const RecoverPartitionsSchema: GenMessage<RecoverPartitions> = /*@__PURE__*/
  messageDesc(file_spark_connect_catalog, 17);

/**
 * See `spark.catalog.isCached`
 *
 * @generated from message spark.connect.IsCached
 */
export type IsCached = Message<"spark.connect.IsCached"> & {
  /**
   * (Required)
   *
   * @generated from field: string table_name = 1;
   */
  tableName: string;
};

/**
 * Describes the message spark.connect.IsCached.
 * Use `create(IsCachedSchema)` to create a new message.
 */
export const IsCachedSchema: GenMessage<IsCached> = /*@__PURE__*/
  messageDesc(file_spark_connect_catalog, 18);

/**
 * See `spark.catalog.cacheTable`
 *
 * @generated from message spark.connect.CacheTable
 */
export type CacheTable = Message<"spark.connect.CacheTable"> & {
  /**
   * (Required)
   *
   * @generated from field: string table_name = 1;
   */
  tableName: string;

  /**
   * (Optional)
   *
   * @generated from field: optional spark.connect.StorageLevel storage_level = 2;
   */
  storageLevel?: StorageLevel;
};

/**
 * Describes the message spark.connect.CacheTable.
 * Use `create(CacheTableSchema)` to create a new message.
 */
export const CacheTableSchema: GenMessage<CacheTable> = /*@__PURE__*/
  messageDesc(file_spark_connect_catalog, 19);

/**
 * See `spark.catalog.uncacheTable`
 *
 * @generated from message spark.connect.UncacheTable
 */
export type UncacheTable = Message<"spark.connect.UncacheTable"> & {
  /**
   * (Required)
   *
   * @generated from field: string table_name = 1;
   */
  tableName: string;
};

/**
 * Describes the message spark.connect.UncacheTable.
 * Use `create(UncacheTableSchema)` to create a new message.
 */
export const UncacheTableSchema: GenMessage<UncacheTable> = /*@__PURE__*/
  messageDesc(file_spark_connect_catalog, 20);

/**
 * See `spark.catalog.clearCache`
 *
 * @generated from message spark.connect.ClearCache
 */
export type ClearCache = Message<"spark.connect.ClearCache"> & {
};

/**
 * Describes the message spark.connect.ClearCache.
 * Use `create(ClearCacheSchema)` to create a new message.
 */
export const ClearCacheSchema: GenMessage<ClearCache> = /*@__PURE__*/
  messageDesc(file_spark_connect_catalog, 21);

/**
 * See `spark.catalog.refreshTable`
 *
 * @generated from message spark.connect.RefreshTable
 */
export type RefreshTable = Message<"spark.connect.RefreshTable"> & {
  /**
   * (Required)
   *
   * @generated from field: string table_name = 1;
   */
  tableName: string;
};

/**
 * Describes the message spark.connect.RefreshTable.
 * Use `create(RefreshTableSchema)` to create a new message.
 */
export const RefreshTableSchema: GenMessage<RefreshTable> = /*@__PURE__*/
  messageDesc(file_spark_connect_catalog, 22);

/**
 * See `spark.catalog.refreshByPath`
 *
 * @generated from message spark.connect.RefreshByPath
 */
export type RefreshByPath = Message<"spark.connect.RefreshByPath"> & {
  /**
   * (Required)
   *
   * @generated from field: string path = 1;
   */
  path: string;
};

/**
 * Describes the message spark.connect.RefreshByPath.
 * Use `create(RefreshByPathSchema)` to create a new message.
 */
export const RefreshByPathSchema: GenMessage<RefreshByPath> = /*@__PURE__*/
  messageDesc(file_spark_connect_catalog, 23);

/**
 * See `spark.catalog.currentCatalog`
 *
 * @generated from message spark.connect.CurrentCatalog
 */
export type CurrentCatalog = Message<"spark.connect.CurrentCatalog"> & {
};

/**
 * Describes the message spark.connect.CurrentCatalog.
 * Use `create(CurrentCatalogSchema)` to create a new message.
 */
export const CurrentCatalogSchema: GenMessage<CurrentCatalog> = /*@__PURE__*/
  messageDesc(file_spark_connect_catalog, 24);

/**
 * See `spark.catalog.setCurrentCatalog`
 *
 * @generated from message spark.connect.SetCurrentCatalog
 */
export type SetCurrentCatalog = Message<"spark.connect.SetCurrentCatalog"> & {
  /**
   * (Required)
   *
   * @generated from field: string catalog_name = 1;
   */
  catalogName: string;
};

/**
 * Describes the message spark.connect.SetCurrentCatalog.
 * Use `create(SetCurrentCatalogSchema)` to create a new message.
 */
export const SetCurrentCatalogSchema: GenMessage<SetCurrentCatalog> = /*@__PURE__*/
  messageDesc(file_spark_connect_catalog, 25);

/**
 * See `spark.catalog.listCatalogs`
 *
 * @generated from message spark.connect.ListCatalogs
 */
export type ListCatalogs = Message<"spark.connect.ListCatalogs"> & {
  /**
   * (Optional) The pattern that the catalog name needs to match
   *
   * @generated from field: optional string pattern = 1;
   */
  pattern?: string;
};

/**
 * Describes the message spark.connect.ListCatalogs.
 * Use `create(ListCatalogsSchema)` to create a new message.
 */
export const ListCatalogsSchema: GenMessage<ListCatalogs> = /*@__PURE__*/
  messageDesc(file_spark_connect_catalog, 26);

