//
// Licensed to the Apache Software Foundation (ASF) under one or more
// contributor license agreements.  See the NOTICE file distributed with
// this work for additional information regarding copyright ownership.
// The ASF licenses this file to You under the Apache License, Version 2.0
// (the "License"); you may not use this file except in compliance with
// the License.  You may obtain a copy of the License at
//
//    http://www.apache.org/licenses/LICENSE-2.0
//
// Unless required by applicable law or agreed to in writing, software
// distributed under the License is distributed on an "AS IS" BASIS,
// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
// See the License for the specific language governing permissions and
// limitations under the License.

// @generated by protoc-gen-es v2.2.3 with parameter "target=ts,import_extension=none,js_import_style=module"
// @generated from file spark/connect/types.proto (package spark.connect, syntax proto3)
/* eslint-disable */

import type { GenFile, GenMessage } from "@bufbuild/protobuf/codegenv1";
import { fileDesc, messageDesc } from "@bufbuild/protobuf/codegenv1";
import type { Message } from "@bufbuild/protobuf";

/**
 * Describes the file spark/connect/types.proto.
 */
export const file_spark_connect_types: GenFile = /*@__PURE__*/
  fileDesc("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");

/**
 * This message describes the logical [[DataType]] of something. It does not carry the value
 * itself but only describes it.
 *
 * @generated from message spark.connect.DataType
 */
export type DataType = Message<"spark.connect.DataType"> & {
  /**
   * @generated from oneof spark.connect.DataType.kind
   */
  kind: {
    /**
     * @generated from field: spark.connect.DataType.NULL null = 1;
     */
    value: DataType_NULL;
    case: "null";
  } | {
    /**
     * @generated from field: spark.connect.DataType.Binary binary = 2;
     */
    value: DataType_Binary;
    case: "binary";
  } | {
    /**
     * @generated from field: spark.connect.DataType.Boolean boolean = 3;
     */
    value: DataType_Boolean;
    case: "boolean";
  } | {
    /**
     * Numeric types
     *
     * @generated from field: spark.connect.DataType.Byte byte = 4;
     */
    value: DataType_Byte;
    case: "byte";
  } | {
    /**
     * @generated from field: spark.connect.DataType.Short short = 5;
     */
    value: DataType_Short;
    case: "short";
  } | {
    /**
     * @generated from field: spark.connect.DataType.Integer integer = 6;
     */
    value: DataType_Integer;
    case: "integer";
  } | {
    /**
     * @generated from field: spark.connect.DataType.Long long = 7;
     */
    value: DataType_Long;
    case: "long";
  } | {
    /**
     * @generated from field: spark.connect.DataType.Float float = 8;
     */
    value: DataType_Float;
    case: "float";
  } | {
    /**
     * @generated from field: spark.connect.DataType.Double double = 9;
     */
    value: DataType_Double;
    case: "double";
  } | {
    /**
     * @generated from field: spark.connect.DataType.Decimal decimal = 10;
     */
    value: DataType_Decimal;
    case: "decimal";
  } | {
    /**
     * String types
     *
     * @generated from field: spark.connect.DataType.String string = 11;
     */
    value: DataType_String;
    case: "string";
  } | {
    /**
     * @generated from field: spark.connect.DataType.Char char = 12;
     */
    value: DataType_Char;
    case: "char";
  } | {
    /**
     * @generated from field: spark.connect.DataType.VarChar var_char = 13;
     */
    value: DataType_VarChar;
    case: "varChar";
  } | {
    /**
     * Datatime types
     *
     * @generated from field: spark.connect.DataType.Date date = 14;
     */
    value: DataType_Date;
    case: "date";
  } | {
    /**
     * @generated from field: spark.connect.DataType.Timestamp timestamp = 15;
     */
    value: DataType_Timestamp;
    case: "timestamp";
  } | {
    /**
     * @generated from field: spark.connect.DataType.TimestampNTZ timestamp_ntz = 16;
     */
    value: DataType_TimestampNTZ;
    case: "timestampNtz";
  } | {
    /**
     * Interval types
     *
     * @generated from field: spark.connect.DataType.CalendarInterval calendar_interval = 17;
     */
    value: DataType_CalendarInterval;
    case: "calendarInterval";
  } | {
    /**
     * @generated from field: spark.connect.DataType.YearMonthInterval year_month_interval = 18;
     */
    value: DataType_YearMonthInterval;
    case: "yearMonthInterval";
  } | {
    /**
     * @generated from field: spark.connect.DataType.DayTimeInterval day_time_interval = 19;
     */
    value: DataType_DayTimeInterval;
    case: "dayTimeInterval";
  } | {
    /**
     * Complex types
     *
     * @generated from field: spark.connect.DataType.Array array = 20;
     */
    value: DataType_Array;
    case: "array";
  } | {
    /**
     * @generated from field: spark.connect.DataType.Struct struct = 21;
     */
    value: DataType_Struct;
    case: "struct";
  } | {
    /**
     * @generated from field: spark.connect.DataType.Map map = 22;
     */
    value: DataType_Map;
    case: "map";
  } | {
    /**
     * @generated from field: spark.connect.DataType.Variant variant = 25;
     */
    value: DataType_Variant;
    case: "variant";
  } | {
    /**
     * UserDefinedType
     *
     * @generated from field: spark.connect.DataType.UDT udt = 23;
     */
    value: DataType_UDT;
    case: "udt";
  } | {
    /**
     * UnparsedDataType
     *
     * @generated from field: spark.connect.DataType.Unparsed unparsed = 24;
     */
    value: DataType_Unparsed;
    case: "unparsed";
  } | { case: undefined; value?: undefined };
};

/**
 * Describes the message spark.connect.DataType.
 * Use `create(DataTypeSchema)` to create a new message.
 */
export const DataTypeSchema: GenMessage<DataType> = /*@__PURE__*/
  messageDesc(file_spark_connect_types, 0);

/**
 * @generated from message spark.connect.DataType.Boolean
 */
export type DataType_Boolean = Message<"spark.connect.DataType.Boolean"> & {
  /**
   * @generated from field: uint32 type_variation_reference = 1;
   */
  typeVariationReference: number;
};

/**
 * Describes the message spark.connect.DataType.Boolean.
 * Use `create(DataType_BooleanSchema)` to create a new message.
 */
export const DataType_BooleanSchema: GenMessage<DataType_Boolean> = /*@__PURE__*/
  messageDesc(file_spark_connect_types, 0, 0);

/**
 * @generated from message spark.connect.DataType.Byte
 */
export type DataType_Byte = Message<"spark.connect.DataType.Byte"> & {
  /**
   * @generated from field: uint32 type_variation_reference = 1;
   */
  typeVariationReference: number;
};

/**
 * Describes the message spark.connect.DataType.Byte.
 * Use `create(DataType_ByteSchema)` to create a new message.
 */
export const DataType_ByteSchema: GenMessage<DataType_Byte> = /*@__PURE__*/
  messageDesc(file_spark_connect_types, 0, 1);

/**
 * @generated from message spark.connect.DataType.Short
 */
export type DataType_Short = Message<"spark.connect.DataType.Short"> & {
  /**
   * @generated from field: uint32 type_variation_reference = 1;
   */
  typeVariationReference: number;
};

/**
 * Describes the message spark.connect.DataType.Short.
 * Use `create(DataType_ShortSchema)` to create a new message.
 */
export const DataType_ShortSchema: GenMessage<DataType_Short> = /*@__PURE__*/
  messageDesc(file_spark_connect_types, 0, 2);

/**
 * @generated from message spark.connect.DataType.Integer
 */
export type DataType_Integer = Message<"spark.connect.DataType.Integer"> & {
  /**
   * @generated from field: uint32 type_variation_reference = 1;
   */
  typeVariationReference: number;
};

/**
 * Describes the message spark.connect.DataType.Integer.
 * Use `create(DataType_IntegerSchema)` to create a new message.
 */
export const DataType_IntegerSchema: GenMessage<DataType_Integer> = /*@__PURE__*/
  messageDesc(file_spark_connect_types, 0, 3);

/**
 * @generated from message spark.connect.DataType.Long
 */
export type DataType_Long = Message<"spark.connect.DataType.Long"> & {
  /**
   * @generated from field: uint32 type_variation_reference = 1;
   */
  typeVariationReference: number;
};

/**
 * Describes the message spark.connect.DataType.Long.
 * Use `create(DataType_LongSchema)` to create a new message.
 */
export const DataType_LongSchema: GenMessage<DataType_Long> = /*@__PURE__*/
  messageDesc(file_spark_connect_types, 0, 4);

/**
 * @generated from message spark.connect.DataType.Float
 */
export type DataType_Float = Message<"spark.connect.DataType.Float"> & {
  /**
   * @generated from field: uint32 type_variation_reference = 1;
   */
  typeVariationReference: number;
};

/**
 * Describes the message spark.connect.DataType.Float.
 * Use `create(DataType_FloatSchema)` to create a new message.
 */
export const DataType_FloatSchema: GenMessage<DataType_Float> = /*@__PURE__*/
  messageDesc(file_spark_connect_types, 0, 5);

/**
 * @generated from message spark.connect.DataType.Double
 */
export type DataType_Double = Message<"spark.connect.DataType.Double"> & {
  /**
   * @generated from field: uint32 type_variation_reference = 1;
   */
  typeVariationReference: number;
};

/**
 * Describes the message spark.connect.DataType.Double.
 * Use `create(DataType_DoubleSchema)` to create a new message.
 */
export const DataType_DoubleSchema: GenMessage<DataType_Double> = /*@__PURE__*/
  messageDesc(file_spark_connect_types, 0, 6);

/**
 * @generated from message spark.connect.DataType.String
 */
export type DataType_String = Message<"spark.connect.DataType.String"> & {
  /**
   * @generated from field: uint32 type_variation_reference = 1;
   */
  typeVariationReference: number;

  /**
   * @generated from field: string collation = 2;
   */
  collation: string;
};

/**
 * Describes the message spark.connect.DataType.String.
 * Use `create(DataType_StringSchema)` to create a new message.
 */
export const DataType_StringSchema: GenMessage<DataType_String> = /*@__PURE__*/
  messageDesc(file_spark_connect_types, 0, 7);

/**
 * @generated from message spark.connect.DataType.Binary
 */
export type DataType_Binary = Message<"spark.connect.DataType.Binary"> & {
  /**
   * @generated from field: uint32 type_variation_reference = 1;
   */
  typeVariationReference: number;
};

/**
 * Describes the message spark.connect.DataType.Binary.
 * Use `create(DataType_BinarySchema)` to create a new message.
 */
export const DataType_BinarySchema: GenMessage<DataType_Binary> = /*@__PURE__*/
  messageDesc(file_spark_connect_types, 0, 8);

/**
 * @generated from message spark.connect.DataType.NULL
 */
export type DataType_NULL = Message<"spark.connect.DataType.NULL"> & {
  /**
   * @generated from field: uint32 type_variation_reference = 1;
   */
  typeVariationReference: number;
};

/**
 * Describes the message spark.connect.DataType.NULL.
 * Use `create(DataType_NULLSchema)` to create a new message.
 */
export const DataType_NULLSchema: GenMessage<DataType_NULL> = /*@__PURE__*/
  messageDesc(file_spark_connect_types, 0, 9);

/**
 * @generated from message spark.connect.DataType.Timestamp
 */
export type DataType_Timestamp = Message<"spark.connect.DataType.Timestamp"> & {
  /**
   * @generated from field: uint32 type_variation_reference = 1;
   */
  typeVariationReference: number;
};

/**
 * Describes the message spark.connect.DataType.Timestamp.
 * Use `create(DataType_TimestampSchema)` to create a new message.
 */
export const DataType_TimestampSchema: GenMessage<DataType_Timestamp> = /*@__PURE__*/
  messageDesc(file_spark_connect_types, 0, 10);

/**
 * @generated from message spark.connect.DataType.Date
 */
export type DataType_Date = Message<"spark.connect.DataType.Date"> & {
  /**
   * @generated from field: uint32 type_variation_reference = 1;
   */
  typeVariationReference: number;
};

/**
 * Describes the message spark.connect.DataType.Date.
 * Use `create(DataType_DateSchema)` to create a new message.
 */
export const DataType_DateSchema: GenMessage<DataType_Date> = /*@__PURE__*/
  messageDesc(file_spark_connect_types, 0, 11);

/**
 * @generated from message spark.connect.DataType.TimestampNTZ
 */
export type DataType_TimestampNTZ = Message<"spark.connect.DataType.TimestampNTZ"> & {
  /**
   * @generated from field: uint32 type_variation_reference = 1;
   */
  typeVariationReference: number;
};

/**
 * Describes the message spark.connect.DataType.TimestampNTZ.
 * Use `create(DataType_TimestampNTZSchema)` to create a new message.
 */
export const DataType_TimestampNTZSchema: GenMessage<DataType_TimestampNTZ> = /*@__PURE__*/
  messageDesc(file_spark_connect_types, 0, 12);

/**
 * @generated from message spark.connect.DataType.CalendarInterval
 */
export type DataType_CalendarInterval = Message<"spark.connect.DataType.CalendarInterval"> & {
  /**
   * @generated from field: uint32 type_variation_reference = 1;
   */
  typeVariationReference: number;
};

/**
 * Describes the message spark.connect.DataType.CalendarInterval.
 * Use `create(DataType_CalendarIntervalSchema)` to create a new message.
 */
export const DataType_CalendarIntervalSchema: GenMessage<DataType_CalendarInterval> = /*@__PURE__*/
  messageDesc(file_spark_connect_types, 0, 13);

/**
 * @generated from message spark.connect.DataType.YearMonthInterval
 */
export type DataType_YearMonthInterval = Message<"spark.connect.DataType.YearMonthInterval"> & {
  /**
   * @generated from field: optional int32 start_field = 1;
   */
  startField?: number;

  /**
   * @generated from field: optional int32 end_field = 2;
   */
  endField?: number;

  /**
   * @generated from field: uint32 type_variation_reference = 3;
   */
  typeVariationReference: number;
};

/**
 * Describes the message spark.connect.DataType.YearMonthInterval.
 * Use `create(DataType_YearMonthIntervalSchema)` to create a new message.
 */
export const DataType_YearMonthIntervalSchema: GenMessage<DataType_YearMonthInterval> = /*@__PURE__*/
  messageDesc(file_spark_connect_types, 0, 14);

/**
 * @generated from message spark.connect.DataType.DayTimeInterval
 */
export type DataType_DayTimeInterval = Message<"spark.connect.DataType.DayTimeInterval"> & {
  /**
   * @generated from field: optional int32 start_field = 1;
   */
  startField?: number;

  /**
   * @generated from field: optional int32 end_field = 2;
   */
  endField?: number;

  /**
   * @generated from field: uint32 type_variation_reference = 3;
   */
  typeVariationReference: number;
};

/**
 * Describes the message spark.connect.DataType.DayTimeInterval.
 * Use `create(DataType_DayTimeIntervalSchema)` to create a new message.
 */
export const DataType_DayTimeIntervalSchema: GenMessage<DataType_DayTimeInterval> = /*@__PURE__*/
  messageDesc(file_spark_connect_types, 0, 15);

/**
 * Start compound types.
 *
 * @generated from message spark.connect.DataType.Char
 */
export type DataType_Char = Message<"spark.connect.DataType.Char"> & {
  /**
   * @generated from field: int32 length = 1;
   */
  length: number;

  /**
   * @generated from field: uint32 type_variation_reference = 2;
   */
  typeVariationReference: number;
};

/**
 * Describes the message spark.connect.DataType.Char.
 * Use `create(DataType_CharSchema)` to create a new message.
 */
export const DataType_CharSchema: GenMessage<DataType_Char> = /*@__PURE__*/
  messageDesc(file_spark_connect_types, 0, 16);

/**
 * @generated from message spark.connect.DataType.VarChar
 */
export type DataType_VarChar = Message<"spark.connect.DataType.VarChar"> & {
  /**
   * @generated from field: int32 length = 1;
   */
  length: number;

  /**
   * @generated from field: uint32 type_variation_reference = 2;
   */
  typeVariationReference: number;
};

/**
 * Describes the message spark.connect.DataType.VarChar.
 * Use `create(DataType_VarCharSchema)` to create a new message.
 */
export const DataType_VarCharSchema: GenMessage<DataType_VarChar> = /*@__PURE__*/
  messageDesc(file_spark_connect_types, 0, 17);

/**
 * @generated from message spark.connect.DataType.Decimal
 */
export type DataType_Decimal = Message<"spark.connect.DataType.Decimal"> & {
  /**
   * @generated from field: optional int32 scale = 1;
   */
  scale?: number;

  /**
   * @generated from field: optional int32 precision = 2;
   */
  precision?: number;

  /**
   * @generated from field: uint32 type_variation_reference = 3;
   */
  typeVariationReference: number;
};

/**
 * Describes the message spark.connect.DataType.Decimal.
 * Use `create(DataType_DecimalSchema)` to create a new message.
 */
export const DataType_DecimalSchema: GenMessage<DataType_Decimal> = /*@__PURE__*/
  messageDesc(file_spark_connect_types, 0, 18);

/**
 * @generated from message spark.connect.DataType.StructField
 */
export type DataType_StructField = Message<"spark.connect.DataType.StructField"> & {
  /**
   * @generated from field: string name = 1;
   */
  name: string;

  /**
   * @generated from field: spark.connect.DataType data_type = 2;
   */
  dataType?: DataType;

  /**
   * @generated from field: bool nullable = 3;
   */
  nullable: boolean;

  /**
   * @generated from field: optional string metadata = 4;
   */
  metadata?: string;
};

/**
 * Describes the message spark.connect.DataType.StructField.
 * Use `create(DataType_StructFieldSchema)` to create a new message.
 */
export const DataType_StructFieldSchema: GenMessage<DataType_StructField> = /*@__PURE__*/
  messageDesc(file_spark_connect_types, 0, 19);

/**
 * @generated from message spark.connect.DataType.Struct
 */
export type DataType_Struct = Message<"spark.connect.DataType.Struct"> & {
  /**
   * @generated from field: repeated spark.connect.DataType.StructField fields = 1;
   */
  fields: DataType_StructField[];

  /**
   * @generated from field: uint32 type_variation_reference = 2;
   */
  typeVariationReference: number;
};

/**
 * Describes the message spark.connect.DataType.Struct.
 * Use `create(DataType_StructSchema)` to create a new message.
 */
export const DataType_StructSchema: GenMessage<DataType_Struct> = /*@__PURE__*/
  messageDesc(file_spark_connect_types, 0, 20);

/**
 * @generated from message spark.connect.DataType.Array
 */
export type DataType_Array = Message<"spark.connect.DataType.Array"> & {
  /**
   * @generated from field: spark.connect.DataType element_type = 1;
   */
  elementType?: DataType;

  /**
   * @generated from field: bool contains_null = 2;
   */
  containsNull: boolean;

  /**
   * @generated from field: uint32 type_variation_reference = 3;
   */
  typeVariationReference: number;
};

/**
 * Describes the message spark.connect.DataType.Array.
 * Use `create(DataType_ArraySchema)` to create a new message.
 */
export const DataType_ArraySchema: GenMessage<DataType_Array> = /*@__PURE__*/
  messageDesc(file_spark_connect_types, 0, 21);

/**
 * @generated from message spark.connect.DataType.Map
 */
export type DataType_Map = Message<"spark.connect.DataType.Map"> & {
  /**
   * @generated from field: spark.connect.DataType key_type = 1;
   */
  keyType?: DataType;

  /**
   * @generated from field: spark.connect.DataType value_type = 2;
   */
  valueType?: DataType;

  /**
   * @generated from field: bool value_contains_null = 3;
   */
  valueContainsNull: boolean;

  /**
   * @generated from field: uint32 type_variation_reference = 4;
   */
  typeVariationReference: number;
};

/**
 * Describes the message spark.connect.DataType.Map.
 * Use `create(DataType_MapSchema)` to create a new message.
 */
export const DataType_MapSchema: GenMessage<DataType_Map> = /*@__PURE__*/
  messageDesc(file_spark_connect_types, 0, 22);

/**
 * @generated from message spark.connect.DataType.Variant
 */
export type DataType_Variant = Message<"spark.connect.DataType.Variant"> & {
  /**
   * @generated from field: uint32 type_variation_reference = 1;
   */
  typeVariationReference: number;
};

/**
 * Describes the message spark.connect.DataType.Variant.
 * Use `create(DataType_VariantSchema)` to create a new message.
 */
export const DataType_VariantSchema: GenMessage<DataType_Variant> = /*@__PURE__*/
  messageDesc(file_spark_connect_types, 0, 23);

/**
 * @generated from message spark.connect.DataType.UDT
 */
export type DataType_UDT = Message<"spark.connect.DataType.UDT"> & {
  /**
   * @generated from field: string type = 1;
   */
  type: string;

  /**
   * @generated from field: optional string jvm_class = 2;
   */
  jvmClass?: string;

  /**
   * @generated from field: optional string python_class = 3;
   */
  pythonClass?: string;

  /**
   * @generated from field: optional string serialized_python_class = 4;
   */
  serializedPythonClass?: string;

  /**
   * @generated from field: spark.connect.DataType sql_type = 5;
   */
  sqlType?: DataType;
};

/**
 * Describes the message spark.connect.DataType.UDT.
 * Use `create(DataType_UDTSchema)` to create a new message.
 */
export const DataType_UDTSchema: GenMessage<DataType_UDT> = /*@__PURE__*/
  messageDesc(file_spark_connect_types, 0, 24);

/**
 * @generated from message spark.connect.DataType.Unparsed
 */
export type DataType_Unparsed = Message<"spark.connect.DataType.Unparsed"> & {
  /**
   * (Required) The unparsed data type string
   *
   * @generated from field: string data_type_string = 1;
   */
  dataTypeString: string;
};

/**
 * Describes the message spark.connect.DataType.Unparsed.
 * Use `create(DataType_UnparsedSchema)` to create a new message.
 */
export const DataType_UnparsedSchema: GenMessage<DataType_Unparsed> = /*@__PURE__*/
  messageDesc(file_spark_connect_types, 0, 25);

